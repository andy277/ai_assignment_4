{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "initial_id",
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import numpy as np\n",
    "from datetime import date\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# 1. Data Processing\n",
   "id": "b70606f94ec68ed8"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "file_path = \"data/House_Prices.csv\"",
   "id": "dfcc902ada0c5adb"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "houses = pd.read_csv(file_path)\n",
    "\n",
    "print(\"Shape:\", houses.shape)\n",
    "houses.head()\n"
   ],
   "id": "c1b8b03933fd9359"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "#### How many rows are there?\n",
    "- There are 10659 rows in total.\n",
    "\n",
    "#### Looks like there are some extra columns with row markers that appeared over the cleaning process.  How many \"actual\" columns are there?\n",
    "- Without counting the \"Unnamed: 0\" column, there are 12 actual columns.\n",
    "\n",
    "#### Why are the dates just numbers?  Why is this ok?\n",
    "- In Excel, dates are stored as **serial numbers** so that it is easier to perform calculations with them.\n",
    "- These numbers represent how many days have passed since a specific start date **(January 1, 1900)**."
   ],
   "id": "e1c7a0e5e94eadc3"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Dropping unused columns\n",
    "df = houses.drop(columns = [\"Unnamed: 0\", \"Record\", \"University\", \"Type2\"])\n",
    "df"
   ],
   "id": "ac0ffb64646d4e07"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# 2. Create Classification Models\n",
   "id": "6f45b7a9244ef098"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "## Set features and target\n",
    "X = df.drop(columns=\"Town\")\n",
    "y = df[\"Town\"]"
   ],
   "id": "a9cb81fe005cc58e"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "## Train, test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ],
   "id": "aa7e50ca9849d5b7"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Decision Tree Classification Model\n",
   "id": "f45215bbdebd4e0"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "def optimize_decision_tree(X_train, y_train, X_test, y_test):\n",
    "    # Initialize variables\n",
    "    best_model = None\n",
    "    best_model_info = None\n",
    "    best_accuracy = 0\n",
    "\n",
    "    ## Explore 3 differemt hyperparameters\n",
    "    min_samples_split_range = [2, 5, 10, 20]\n",
    "    depths = list(range(1, 16))\n",
    "    criteria = ['gini', 'entropy']\n",
    "\n",
    "    \n",
    "    # Using nested loops to try out different parameters to find the best model with lowest error\n",
    "    for depth in depths:\n",
    "       for min_samples_split in min_samples_split_range:\n",
    "           for criterion in criteria:\n",
    "                # Train the model\n",
    "                model = DecisionTreeClassifier(max_depth=depth, random_state=42, min_samples_split=min_samples_split, criterion=criterion)\n",
    "                \n",
    "                #Cross validation scores\n",
    "                cv_scores = cross_val_score(model, X_train, y_train, cv=5)\n",
    "                avg_cv_scores = cv_scores.mean()\n",
    "               \n",
    "                #Train model\n",
    "                model.fit(X_train, y_train)\n",
    "                \n",
    "                # Predicting on train and test set\n",
    "                train_pred = model.predict(X_train)\n",
    "                test_pred = model.predict(X_test)\n",
    "\n",
    "                #Calculate accuracy\n",
    "                train_accuracy = accuracy_score(y_train, train_pred)\n",
    "                test_accuracy = accuracy_score(y_test, test_pred)\n",
    "                \n",
    "                #find best model\n",
    "                if test_accuracy > best_accuracy:\n",
    "                    best_accuracy = test_accuracy\n",
    "                    best_model = model\n",
    "                    best_model_info = {\n",
    "                        \"min_samples_split\": min_samples_split,\n",
    "                        \"depth\": depth,\n",
    "                        \"criteria\": criterion,\n",
    "                        \"cv_scores\": cv_scores,\n",
    "                        \"avg_cv_scores\": avg_cv_scores,\n",
    "                        \"train_accuracy\": train_accuracy,\n",
    "                        \"test_accuracy\": test_accuracy\n",
    "                        \n",
    "                    }\n",
    "    \n",
    "    # Return the best model and its info \n",
    "    return best_model, best_model_info"
   ],
   "id": "5f5b596be796f4fb"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### Note:\n",
    "- I took this code from our previous assignment and adjusted it a little bit in order to find the best possible Decision Tree model"
   ],
   "id": "1fc3e93f689fdb40"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Random Forest Classification Model\n",
   "id": "3a9cf0832fefa6c8"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "def optimize_rf(X_train, y_train, X_test, y_test):\n",
    "    # initialize variables\n",
    "    n_estimators_options = [50, 100, 200, 500]\n",
    "    max_depth_options = range(1, 16, 2)\n",
    "\n",
    "    best_accuracy = 0\n",
    "    best_model_info = None\n",
    "    best_model = None\n",
    "    \n",
    "    # Try out different params to find best model\n",
    "    for n_estimators in n_estimators_options:\n",
    "        for max_depth in max_depth_options:\n",
    "            # Create model\n",
    "            model = RandomForestClassifier(n_estimators=n_estimators, max_depth=max_depth, random_state=42)\n",
    "            \n",
    "            # Cross validation score\n",
    "            cv_scores = cross_val_score(model, X_train, y_train, cv=5)\n",
    "            avg_cv_scores = cv_scores.mean()\n",
    "            \n",
    "            #Train model\n",
    "            model.fit(X_train, y_train)\n",
    "            test_score = model.score(X_test, y_test)\n",
    "            \n",
    "            #Predicting on train and test sets\n",
    "            train_pred = model.predict(X_train) \n",
    "            test_pred = model.predict(X_test)\n",
    "            \n",
    "            #Calculate accuracy\n",
    "            train_accuracy = accuracy_score(y_train, train_pred)\n",
    "            test_accuracy = accuracy_score(y_test, test_pred)\n",
    "            \n",
    "            # Find best model\n",
    "            if test_accuracy > best_accuracy:\n",
    "                best_model = model\n",
    "                best_model_info = {\n",
    "                    \"n_estimators\": n_estimators,\n",
    "                    \"max_depth\": max_depth,\n",
    "                    \"test_score\": test_score,\n",
    "                    \"cv_scores\": cv_scores,\n",
    "                    \"avg_cv_scores\": avg_cv_scores,\n",
    "                    \"train_accuracy\": train_accuracy,\n",
    "                    \"test_accuracy\": test_accuracy\n",
    "                }\n",
    "    #Return best model and its info\n",
    "    return best_model, best_model_info"
   ],
   "id": "16efa5f344e7c856"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-11T07:14:36.901728Z",
     "start_time": "2025-02-11T07:14:36.821225Z"
    }
   },
   "cell_type": "code",
   "source": [
    "%%time\n",
    "best_model_rf, best_model_info_rf = optimize_rf(X_train, y_train, X_test, y_test)\n",
    "best_model_info_rf"
   ],
   "id": "dcfb3113153fb679",
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'optimize_rf' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mNameError\u001B[0m                                 Traceback (most recent call last)",
      "File \u001B[1;32m<timed exec>:1\u001B[0m\n",
      "\u001B[1;31mNameError\u001B[0m: name 'optimize_rf' is not defined"
     ]
    }
   ],
   "execution_count": 1
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "%%time\n",
    "best_model_dc, best_model_info_dc = optimize_decision_tree(X_train, y_train, X_test, y_test)\n",
    "best_model_info_dc"
   ],
   "id": "c28e5de1dd8457d3"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### Model Explanation\n",
    "For both models, I picked out the most reasonable parameter options and loop through to ultimately find the best model for each classification algorithm. After optimizing both **Decision Tree** and **Random Forest** models, I compared their performance and decided to use **Random Forest** for the Lee's house prediction. \n",
    "#### Decision Tree:\n",
    "- **Train Accuracy**: 0.56\n",
    "- **Test Accuracy**: 0.29\n",
    "- **Average Cross-Validation Score**: 0.39\n",
    "\n",
    "#### Random Forest:\n",
    "- **Train Accuracy**: 0.99\n",
    "- **Test Accuracy**: 0.40\n",
    "- **Average Cross-Validation Score**: 0.40\n",
    "\n",
    "After comparing the performance of both models, I picked **Random Forest** as my model for the prediction because its accuracy is around 15-20% better than **Decision Tree**.\n",
    "\n",
    "#### Was your testing accuracy as good as your training?  What did you think happened?\n",
    "The Random Forest model achieved a **training accuracy of 0.99** but a much lower **testing accuracy of 0.40**, indicating **overfitting**. This means the model memorized the training data instead of learning general patterns, leading to poor performance on unseen data. The average **cross-validation score of 0.40** confirms this issue."
   ],
   "id": "be844542ca4dfbab"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# 3. Making Prediction\n",
   "id": "51bec22ef428f5e8"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Lee's House\n",
    "Lee purchased a 1,450 sq ft Single Family home (coded as 3) on 2018-04-11, (43201) for $350,000.  The house has 3 bedrooms and 2 baths.  It was built in 1992, and is on a 40,000 square foot lot.  What town do you think it is in?  Use your model to predict."
   ],
   "id": "cc0ae50d9bc3f625"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Creating Lee House DataFrame\n",
    "lee_house = pd.DataFrame({\n",
    "    'Sale_amount': [350000],\n",
    "    'Sale_date': [43201],\n",
    "    'Beds': [3],\n",
    "    'Baths': [2],\n",
    "    'Sqft_home': [1450],\n",
    "    'Sqft_lot': [40000],\n",
    "    'Type': [3],\n",
    "    'Build_year': [1992]\n",
    "})"
   ],
   "id": "b392ad30637f31f7"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Using Random Forest to predict\n",
    "predicted_town = best_model_rf.predict(lee_house)\n",
    "print(\"Predicted Town: \", predicted_town[0])"
   ],
   "id": "1ad6739bbb92783c"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
